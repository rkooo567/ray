# An unique identifier for the head node and workers of this cluster.
cluster_name: shuffling-data-loader-horovod

# The maximum number of workers nodes to launch in addition to the head
# node. This takes precedence over min_workers. min_workers default to 0.
min_workers: 1
initial_workers: 1
max_workers: 10

# target_utilization_fraction: 0.9

# If a node is idle for this many minutes, it will be removed.
idle_timeout_minutes: 20
docker:
    image: horovod/horovod-ray:sha-3278964 # 7/20
    container_name: ray_docker

# Cloud-provider specific configuration.
provider:
    type: aws
    region: us-west-2
    # region: us-east-2
    # availability_zone: us-east-2a
    cache_stopped_nodes: False # If not present, the default is True.

# How Ray will authenticate with newly launched nodes.
auth:
    ssh_user: ubuntu

head_node_type: head

available_node_types:
    head:
        node_config:
            InstanceType: g3.4xlarge
            ImageId: latest_dlami
            # Set primary volume to 25 GiB
            BlockDeviceMappings:
                - DeviceName: /dev/sda1
                  Ebs:
                      VolumeSize: 300

    gpu_nodes:
        min_workers: 0
        # The maximum number of worker nodes of this type to launch.
        # This takes precedence over min_workers.
        max_workers: 3
        node_config:
            InstanceType: g3.4xlarge
            ImageId: latest_dlami
            IamInstanceProfile:
                Arn: arn:aws:iam::959243851260:instance-profile/ray-autoscaler-v1
            BlockDeviceMappings:
                - DeviceName: /dev/sda1
                  Ebs:
                      VolumeSize: 300

    memory_nodes:
        min_workers: 0
        # The maximum number of worker nodes of this type to launch.
        # This takes precedence over min_workers.
        max_workers: 4
        node_config:
            InstanceType: m5.16xlarge
            ImageId: latest_dlami
            IamInstanceProfile:
                Arn: arn:aws:iam::959243851260:instance-profile/ray-autoscaler-v1
            BlockDeviceMappings:
                - DeviceName: /dev/sda1
                  Ebs:
                      VolumeSize: 300
    # Run workers on spot by default. Comment this out to use on-demand.
    # InstanceMarketOptions:
    #     MarketType: spot
        # SpotOptions:
        #     MaxPrice: "9.0"

file_mounts: {
  # ".": "."
}

setup_commands:
    # - pip install -q boto3 tqdm torch torchvision  pyarrow fsspec s3fs==2021.08.0
    - pip uninstall ray -y && pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-2.0.0.dev0-cp37-cp37m-manylinux2014_x86_64.whl
   
# Custom commands that will be run on the head node after common setup.
head_setup_commands: []

# Custom commands that will be run on worker nodes after common setup.
worker_setup_commands: []

# # Command to start ray on the head node. You don't need to change this.
head_start_ray_commands:
    - ray stop --force
    - rm -rf /tmp/ray/
    - RAY_BACKEND_LOG_LEVEL=debug ray start --head --port=6379 --object-manager-port=8076 --autoscaling-config=~/ray_bootstrap_config.yaml 

# Command to start ray on worker nodes. You don't need to change this.
worker_start_ray_commands:
    - ray stop --force
    - rm -rf /tmp/ray/
    - RAY_BACKEND_LOG_LEVEL=debug ray start --address=$RAY_HEAD_IP:6379 --object-manager-port=8076